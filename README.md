# Прогнозирование повторных покупок в течение 30 дней

 # Описание
 Заказчик предоставил обезличенные данные по истории покупок трех интернет-магазинов

 # Цель проекта:
 В рамках проекта нужно разработать решение, которое будет предсказывать, совершит ли пользователь повторную покупку в течение 30 дней.

 # Краткий план работы:
 - загрузить и изучить предоставленные данные

- создать полезные признаки для обучения модели

- создать целевой признак – повторная покупка в течение 30 дней

- предложить и обосновать метрику

- обучить модель

- протестировать и проверить модель на адекватность

**Задача 1 - покупки в следующие 30 дней**, то есть клиент совершает повторную покупку в течение 30 последних дней отчетного периода

- Цели:
Прогноз спроса: Оценка того, какие товары клиент, скорее всего, приобретет в ближайшие 30 дней.
Оптимизация запасов: Планирование и управление запасами товаров на складе или торговой сети с учетом предсказанного спроса, построение и обновление планов производства (для мобильного производства), управление закупками необходимого товара.
Улучшение эффективности поставок: Оптимизация логистических и поставочных цепочек на основе ожидаемого спроса.
- Возможные подходы:
Обучение моделей машинного обучения, учитывающих различные факторы, влияющие на заказы клиента.
- Преимущества:
Эффективное управление запасами: Сокращение дефицита товаров и избыточных запасов.
Увеличение удовлетворенности клиентов: Предложение клиентам того, что им действительно нужно.

Разметка данных:
Выбрали все уникальные даты датасета и отделили из основной выборки последних 30 дней. Удалили из основного датасета последние 30 дней. Получили список уникальных пользователей, сделавших покупку в последние 30 дней. Цель - определить, кто из клиентов проявил активность в последние 30 уникальных дней. Этот список будет использовали для создания целевой переменной. В столбце target значения 1 - для пользователей, которые совершили покупку в течение последних 30 дней, и 0 - для остальных пользователей.

В качестве лучшей на кроссвалидации модель, взяли модель, построенную на базе алгоритма машинного обучения LGBMClassifier. Получили достаточно высокие показатели по всем метрикам. Возможно модель переобучилась. Есть доминирующий фактор, сильно выделяющийся из общей статистики is_high_sales_month_1.0 (10 факторов из 28 влияют на результат модели в диапозоне от 14 до 26%). Модель не только показывает хорошие результаты, но и достаточно моневрена:при увеличении доли правильно опознаных клиентов класса 1 на 10%, дополнительно получаем 19% ложных срабатываний:
- порог 50% - верное определение класса 1 60%, ложные срабатывания 13%
- порог 35% - верное опредление класса 1 70%, ложные срабатывания 32%

**Проверка лучшей модели на тестовой выборке**

Результат на тесте модели алгоритма LGBMClassifierоказался немного хуже, чем на валидации. С точки зрения привлечения средств на маркетинговые акции - в 30% случаев они будут нецелесообразными. Примерно половину клиентов класса 1 (0,53) модель определяет верно и еще 30% клиентов класса 0 модель приписывает к классу 1 (precision = 0,69).

В поиске новых моделей обратились к моделе алгоритма RandomForestClassifier и проверили результаты на тесте. Результат на тесте показывает, что модель определяет 71% клиентов класса 1, при этом ошибка при определении класса 1 составляет 6% (это клиенты класса 0). Результат очень хороший. Все-таки необходимо учесть большое влияние фактора non_season_percentage на модель и удалив его с модели посмотреть на результаты.

**Дополнительные исследования**

Рассмотрели влияние столбцов с высокой корреляцией на работу не линейных моделей. Удалили из датасета следующие столбцы: nunique_items_per_orders, avg_days_between_orders, min_days_between_orders, max_days_between_orders, min_price_per_orders, max_price_per_orders, non_season_percentage, high_load_days_percentage.
На модель алгортма RandomForestClassifier в совокупности эти признаки оказвали влияние в размере 64%. Новая модель алгоритмаRandomForestClassifier натренированная на трейне без признаков с высокой корреляцией показывает такие же высокие метрики как и раньше Precision - 0.99, Recall -0.92, проявляя себя как перобученная модель, хотя ранее метрики на тесте нам понравились. После удаления части признаков у модели RandomForestClassifier наблюдаем увеличение влияния других факторов, например признак orders_count - 35%, который выдает количество совершенных покупателем заказов за отчетный период. Результат на тесте хороший. Хоть процент распознания класса 1 немного уменьшился и составляет 65% (на 6% , но доля ложных срабатываний практически не изменилась -7%.
Использование порога опредления классов показало, что модель мобильна.Например, что б на 10% увеличить количество правильно подобранных клиентов, которые обязательно совершат покупку в последние 30 дней отчетного периода нужно порог опредления класса снизит до 35%, при этом расходы на маркетинговую акцию увеличатся на 12%. (При пороге 35% Recall - 0,74 (было 65%) клиентов класса 1 будет определено верно, 19% (было 7%) будет определено как класс 1 ошибочно(Precision - 0,81).
Далее расматривали поведение алгоритмов машинного обучения LGBMClassifier, на датасете без признаков с высокой корреляцией.

Наблюдаем такую же хорошую реакцию модели на предложенные факторы. Все (оставшие) признаки весомо учавствуют в формировании предсказательной системы.
Незначительно, но в лучшую сторону изменилась доля верно предсказанных клиентов 1 класса среди всех предсказанных как 1 класс - 0,71, а значит на 2% уменьшилось количество ложных предсказаний. Доля правильно предсказанного 1 класса для клиентов 1 класса не изменилась и составляет 53%.
Эта модель дает возможность в зависимости от задачи менять порог определения классов. Но экономическая эффективность от изменения порога намного хуче, чем у модели алгоритма машинного обучения RandomForestClassifier. Например: чтоб достичь эффекта - увеличить число верно определяемых покупателей класса 1 на 9%, то есть дойти до 62% (было на 50%-ом пороге 53%), необходимо порог снизить до отметки 20%, а маркетинговые затраты на привлечение увеличатся на 21% (50% клиентов не отреагируют на рассылку, то есть количество ложных срабатываний увеличится на 21% - с 29% до 50%).
Визуализация распределения вероятности трейна аналогична тесту.
Построили график, на котором можно отследить, как меняются значения precision и recall при изменении порога классификации. Так как линия Preprecisioncision возрастающая и верхняя точка этой линии показывает 0,78, можно сказать что добиться уменьшения ложных срабатываний меньше чем 22% не удастся.
Кривая ROC показывает высокую производительность классификатора.
Так можно анализировать все модели и их метрики, изучать влияние факторов, поведение метрик при изменении порога определения класса.

Мы работали с тремя датасетами. Результаты значительно не отличались, по этому за основу взяли датасет по заказм за день. методы борьбы с дисбалансом классов особых результатов не принесли.

**Задача 2 - повторная покупка в течение 30 дней после заказа**

- Цели:
Удержание клиентов: Стимулирование повторных покупок для удержания клиентов на платформе или в магазине.
Максимизация выручки: Повышение доходности за счет частых и регулярных заказов.
- Возможные подходы:
Программы лояльности: Внедрение программ лояльности с бонусами, скидками или специальными предложениями для постоянных клиентов.
Персонализированный маркетинг: Использование данных о предпочтениях клиентов для создания персонализированных предложений и акций.
Предсказание жизненного цикла клиента: Использование аналитики для предсказания момента, когда клиент склонен сделать повторный заказ.
Модели прогнозирования временных рядов: Использование методов временных рядов для прогнозирования будущих заказов на основе исторических данных.
- Преимущества:
Стабильный доход: Постоянные заказы от постоянных клиентов.
Увеличение лояльности: Клиенты, склонные к повторным покупкам, более лояльны к бренду.

Разметка данных - два варианта:
- если клиент в течение 30 дней сделает повторную покупку то целевая переменная равна 1, в остальных случаях -0
- тоже самое, но учли, что для последней покупки нет данных как будут развиваться события далее, поэтому последние покупки у всех клиентов удалили. У нас два датасета для работы с моделями.

На основе предоставленных данных и обобщенных метрик, модель LGBM XGBClassifier без ресемплинга выглядит как перспективный выбор (на двух наборах данных):
- высокие значения Precision = 0.67, Recall = 0.67 и F1 Score = 0.72
Датасет, в котором удалили последние заказы, показал себя лучше. Это связано в первую очередь с тем, что не было дисбаланса классов. Так же это говорит о том, что большая часть повторных покупок, как и говорилось ранее, совершается в период 30 дней от первой покупки.

Провели анализ влияния факторов, признак referred_product_cluster_2 показывает самую большую меру влияния -0.38

При пороге 50% модель верно определяет клиентов которые совершат покупку в течение 30 последующих дней в 59% случаев класса 1 и ложный выбор составляет 5%. Снижая порог до 30% мы поднимаем узнаваемость класса1 до 77% (на 22%), на эту сумму дополнительно распознаных клиентов припадет дополнительных расходов на 11%, то есть 18% покупателей будет определено неверно и отнесено к классу 1.

Проанализировали все модели и сделали следующие выводы:
Модели нужно рассматривать не только с точки зрения высоких метрик, но и динамичности модели (то есть способности модель в в лучшую, с экономической точки зрения, сторону менять метрики от смены порога), то рейтинг рассмотренных моделей можно распредлить следующим образом:

RandomForestClassifier на усеченной выборке, где:
- порог 50% -97% узнаваемости класса1 и 1% ложных срабатываний
- порог 45% - 99% узнаваемости класса1 и 3% ложных срабатываний
- 
RandomForestClassifier на полной выборке,
- порог 50% -90% узнаваемости класса1 и 1% ложных срабатываний
- порог 25% - 99% узнаваемости класса1 и 13% ложных срабатываний
- 
XGBClassifier на усеченной выборке, где:
- порог 50% -76% узнаваемости класса1 и 20% ложных срабатываний
- порог 30% - 99% узнаваемости класса1 и 42% ложных срабатываний У остальных рассмотренных ситуация хуже. У всех этих моделей вовлеченность признаков не превышает 14%.
- 
Проверили результаты работы модели RandomForestClassifier на усеченной выборкена тестовой выборке. резальта хуже, чем на трейне:
- верных ответов 56%, ложных срабатываний 6%. (Precision = 0.94, Recall = 0.56).

Прошлись по значениям метрик на разных порогах определения класса: Так при увеличении числа правильно опредленных клиентов класса 1 на 16% (порог 45%, станет  Recall = 0,71 правильно определенных клиентов класса 1), дополнительные потери от ложно- определенных клиентов составят чуть более 1% (Precisionстанет 0,93 ).

Такую же работу провели для модели RandomForestClassifier на полной выборке:
результат на тесте плохой: определяем верно только 27% клиентов класса 1, ложновыявленные составляют 31%. (Precision = 0.69, Recall = 0.27) -при смене порога ситуация сильно не меняется:
- порог 50% -27% узнаваемости класса 1 и 31% ложных срабатываний
- порог 25% - 61% узнаваемости класса 1 и 54% ложных срабатываний
- 
Распределение вероятностей на тренировочном и тестовом наборе данных сильно различается, это может быть сигналом проблемы с обобщением модели на новые данные.На трейне 1 класс можно определить преребором порога, при этом чем ближе к концам числовой прямой 0-1, тем частота выше. это говорит об отсутсвии системности в данных, проследить принципальные особенности сложно.На тесте гарфик с высокой частотой от 0,4 до 0,8, скошен в право, хвост в лево. Это может говорить о том, что на тестовых данных есть большое количество объектов с вероятностями в указанном интервале, и, возможно, наша модель становится менее уверенной при присвоении классов за пределами этого интервала.

Распределение классов в тесте значительно отличается от трейна. В тренировочном наборе данных отсутствует дисбаланс, модель может не учесть возможное изменение баланса в тестовых данных, даже если рассматривать модель с методами борьбы с дисбалансом. В этом случае результаты модели могут быть не такими, как ожидалось, когда дисбаланс появляется в новых данных Данная проблема говорит о том, что строить такого рода предсказательные модели, имея ограниченный временной период, чревато провалама для модели в предсказаниях на тесте.

Признаки is_high_load_day_2 и is__non_season_2 (-17% и -14%): имеют значительное различие в важности между тестовыми и тренировочными данными. Возможно, внешние факторы, которые влияют на эти признаки, меняются в тестовом сете по сравнению с тренировочным. Так как по факту мы анализируем уже свершившиеся маркетинговые акции, то велика вероятность того, что акции проводились не с упром на какие-то определенные дни или сезоны, а мере возникшей необходимости.Стоит обратить внимание на стабильность этих признаков в реальных условиях работы.

На основе результатов тестирования и статистического анализа можно сделать следующие выводы: Признаки, которые оказsвали значительное влияние на работу модели изменили свое распределение, в общей сложности 17 признаков притерпели изменение в распределение данных. То есть на результаты модели на тестовых данных изменение структуры тестового датасета повлияло достаточно серьезно.

Ни смотря на низкие предсказания на тесте модели RandomForestClassifier на полной выборке, графики показывают более стабильное и понятное состояние метрик.
Модель RandomForestClassifier на усеченой выборке хоть и показывает лучше результат, но все же возникает мысль, что модель переобучилась, так же причиной низкого по сравнению с трейном уровня метрик можно считать сущетсвенные различия в распредлении даных теста и трейна.
 
